{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text similarity app\tCosine similarity, semantic matching\tQuora questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USED THIS CODE TO UNZIP THE TEST AND SUBMISSION .CSV FILES AND AFTER EXTRACTION I DELETED THE ZIP FILES FROM DIRECTORY SO AFTER DELETION THIS CODE DOESNT WORKS\n",
    "# import zipfile\n",
    "# import os\n",
    "# project_dir=r\"C:\\Users\\LENOVO\\Desktop\\NN_projects\\level3ML\\textsimilarityApp\\data\\quora-question-pairs\"\n",
    "# zip_files=[\"train.csv.zip\",\"sample_submission.csv.zip\"]\n",
    "# for zip_name in zip_files:\n",
    "#     zip_path=os.path.join(project_dir,zip_name)\n",
    "#     with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
    "#         zip_ref.extractall(project_dir)#Extracting zip files inside the project directory\n",
    "#         print(f\"{zip_name} unzipped successfully .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')  \n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50279fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if (pd.isna(text)):\n",
    "        return \"\"\n",
    "    text=text.lower()#converting all the text to lowercase\n",
    "    text=re.sub(r'[^a-zA-Z0-9\\s]',\" \",text)#Rempoving all special characters\n",
    "    text=re.sub(r'\\s+',\" \",text).strip()#removing extra spaces\n",
    "    return text\n",
    "train_df['question1']=train_df['question1'].apply(clean_text)\n",
    "train_df['question2']=train_df['question2'].apply(clean_text)\n",
    "test_df['question1']=test_df['question1'].apply(clean_text)\n",
    "test_df['question2']=test_df['question2'].apply(clean_text)\n",
    "print(train_df.head())\n",
    "print(train_df['question1'][0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stopwords=set(stopwords.words('english'))\n",
    "print(stopwords)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ddb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    filtered_tokens=[word for word in tokens if word not in stopwords]\n",
    "    filtered_text=\" \".join(filtered_tokens)\n",
    "    return filtered_text\n",
    "train_df['question1']=train_df['question1'].apply(remove_stopwords)\n",
    "train_df['question2']=train_df['question2'].apply(remove_stopwords)\n",
    "test_df['question1']=test_df['question1'].apply(remove_stopwords)\n",
    "test_df['question2']=test_df['question2'].apply(remove_stopwords)\n",
    "print(train_df['question1'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3379859",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_base(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(words) for words in tokens]\n",
    "    lemmatized_text=\" \".join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "train_df['question1']=train_df['question1'].apply(reduce_to_base)\n",
    "train_df['question2']=train_df['question2'].apply(reduce_to_base)\n",
    "test_df['question1']=test_df['question1'].apply(reduce_to_base)\n",
    "test_df['question2']=test_df['question2'].apply(reduce_to_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simple_features(df):\n",
    "    #Compute length differrence and common word features\n",
    "    df['lenq1']=df['question1'].apply(lambda x:len(x.split()))#no of words in q1\n",
    "    df['lenq2']=df['question2'].apply(lambda x:len(x.split()))#no of words in q2\n",
    "    df['len_diff']=abs(df['lenq1']-df['lenq2'])#Absolute length difference\n",
    "    #no of common words\n",
    "    df['common_words']=df.apply(lambda row :len(set(row['question1'].split()).intersection(set(row['question2'].split()))),axis=1)\n",
    "    return df\n",
    "train_df=compute_simple_features(train_df)\n",
    "test_df=compute_simple_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_tfidf_cosine_similarity(train_df,test_df):\n",
    "#     #compute cosine similarity of tfIDf vectors of question pairs\n",
    "#     #Combine all questions to fit the TF-IDF vectorizer\n",
    "#     all_questions=pd.concat([train_df['question1'],train_df['question2'],test_df['question1'],test_df['question2']])\n",
    "#     tfidf_vectorizer=TfidfVectorizer()\n",
    "#     tfidf_vectorizer.fit(all_questions)\n",
    "#     #Transform questions to TF-IDF vectors\n",
    "#     train_q1_tfidf=tfidf_vectorizer.transform(train_df['question1'])\n",
    "#     train_q2_tfidf=tfidf_vectorizer.transform(train_df['question2'])\n",
    "#     test_q1_tfidf=tfidf_vectorizer.transform(test_df['question1'])\n",
    "#     test_q2_tfidf=tfidf_vectorizer.transform(test_df['question2'])\n",
    "#     #Compute cosine similarity\n",
    "#     train_df['tfidf_cosine_sim']=[cosine_similarity(train_q1_tfidf[i],train_q2_tfidf[i])[0][0] for i in range(len(train_df))]\n",
    "#     test_df['tfidf_cosine_sim']=[cosine_similarity(test_q1_tfidf[i],test_q2_tfidf[i])[0][0] for i in range(len(test_df))]\n",
    "#     return train_df,test_df\n",
    "# train_df,test_df=compute_tfidf_cosine_similarity(train_df,test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf_cosine_similarity(train_df, test_df, max_features=20000):\n",
    "    # Combine all questions to fit the TF-IDF vectorizer\n",
    "    all_questions = pd.concat([\n",
    "        train_df['question1'], train_df['question2'],\n",
    "        test_df['question1'], test_df['question2']\n",
    "    ])\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    tfidf_vectorizer.fit(all_questions)\n",
    "    \n",
    "    # Transform train & test questions\n",
    "    train_q1_tfidf = tfidf_vectorizer.transform(train_df['question1'])\n",
    "    train_q2_tfidf = tfidf_vectorizer.transform(train_df['question2'])\n",
    "    test_q1_tfidf = tfidf_vectorizer.transform(test_df['question1'])\n",
    "    test_q2_tfidf = tfidf_vectorizer.transform(test_df['question2'])\n",
    "    \n",
    "    # Normalize rows (L2 norm = 1), so dot product = cosine similarity\n",
    "    train_q1_norm = normalize(train_q1_tfidf)\n",
    "    train_q2_norm = normalize(train_q2_tfidf)\n",
    "    test_q1_norm = normalize(test_q1_tfidf)\n",
    "    test_q2_norm = normalize(test_q2_tfidf)\n",
    "    \n",
    "    # Compute cosine similarity as row-wise dot product (fast!)\n",
    "    train_df['tfidf_cosine_sim'] = (train_q1_norm.multiply(train_q2_norm)).sum(axis=1).A1\n",
    "    test_df['tfidf_cosine_sim'] = (test_q1_norm.multiply(test_q2_norm)).sum(axis=1).A1\n",
    "    \n",
    "    return train_df, test_df\n",
    "train_df,test_df=compute_tfidf_cosine_similarity(train_df,test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d983b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_embedding_similarity(train_df, test_df,batch_size=128):\n",
    "#     #initialize model with gpu support\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "    \n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     print(\"Computing embeddings for training data...\")\n",
    "#     train_q1_embeddings = model.encode(train_df['question1'].tolist(),batch_size=batch_size, show_progress_bar=True, convert_to_tensor=True,device=device)\n",
    "#     train_q2_embeddings = model.encode(train_df['question2'].tolist(),batch_size=batch_size, show_progress_bar=True, convert_to_tensor=True,device=device)\n",
    "\n",
    "#     print(\"Computing embeddings for test data...\")\n",
    "#     test_q1_embeddings = model.encode(test_df['question1'].tolist(),batch_size=batch_size, show_progress_bar=True, convert_to_tensor=True,device=device)\n",
    "#     test_q2_embeddings = model.encode(test_df['question2'].tolist(),batch_size=batch_size, show_progress_bar=True, convert_to_tensor=True,device=device)\n",
    "\n",
    "#     #  Vectorized cosine similarity \n",
    "#     # Normalize embeddings \n",
    "#     train_q1_norm = torch.nn.functional.normalize(train_q1_embeddings, dim=1)\n",
    "#     train_q2_norm = torch.nn.functional.normalize(train_q2_embeddings, dim=1)\n",
    "#     test_q1_norm = torch.nn.functional.normalize(test_q1_embeddings, dim=1)\n",
    "#     test_q2_norm = torch.nn.functional.normalize(test_q2_embeddings, dim=1)    \n",
    "\n",
    "#     # Cosine similarity = dot product after normalization\n",
    "#     train_sim = torch.sum(train_q1_norm * train_q2_norm, dim=1)\n",
    "#     test_sim  = torch.sum(test_q1_norm * test_q2_norm, dim=1)\n",
    "\n",
    "#     # Store results\n",
    "#     train_df['embedding_cosine_similarity'] = train_sim.cpu().numpy()\n",
    "#     test_df['embedding_cosine_similarity'] = test_sim.cpu().numpy()\n",
    "\n",
    "#         # Clear GPU memory\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#     return train_df, test_df\n",
    "# train_df, test_df = compute_embedding_similarity(train_df, test_df,batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_similarity(train_df, test_df, batch_size=32, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Memory-optimized GPU embedding computation with chunking and error handling\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    try:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Clear GPU cache before starting\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # Function to process data in chunks\n",
    "        def process_in_chunks(texts, description=\"Processing\", current_batch_size=batch_size):\n",
    "            embeddings_list = []\n",
    "            \n",
    "            for i in range(0, len(texts), chunk_size):\n",
    "                chunk_texts = texts[i:i+chunk_size]\n",
    "                chunk_num = i//chunk_size + 1\n",
    "                total_chunks = (len(texts)-1)//chunk_size + 1\n",
    "                print(f\"{description} chunk {chunk_num}/{total_chunks} (size: {len(chunk_texts)})\")\n",
    "                \n",
    "                try:\n",
    "                    chunk_embeddings = model.encode(\n",
    "                        chunk_texts,\n",
    "                        batch_size=current_batch_size,\n",
    "                        show_progress_bar=True,\n",
    "                        convert_to_tensor=True,\n",
    "                        device=device\n",
    "                    )\n",
    "                    embeddings_list.append(chunk_embeddings)\n",
    "                    \n",
    "                    # Clear cache after each chunk\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e).lower():\n",
    "                        print(f\"GPU OOM error. Reducing batch size from {current_batch_size} to {current_batch_size//2}\")\n",
    "                        current_batch_size = max(1, current_batch_size//2)\n",
    "                        \n",
    "                        # Clear cache and retry\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        # Retry with smaller batch\n",
    "                        chunk_embeddings = model.encode(\n",
    "                            chunk_texts,\n",
    "                            batch_size=current_batch_size,\n",
    "                            show_progress_bar=True,\n",
    "                            convert_to_tensor=True,\n",
    "                            device=device\n",
    "                        )\n",
    "                        embeddings_list.append(chunk_embeddings)\n",
    "                    else:\n",
    "                        raise e\n",
    "                        \n",
    "            # Concatenate all chunks\n",
    "            return torch.cat(embeddings_list, dim=0)\n",
    "        \n",
    "        # Process training data in chunks\n",
    "        print(\"Computing embeddings for training questions...\")\n",
    "        train_q1_embeddings = process_in_chunks(\n",
    "            train_df['question1'].tolist(),\n",
    "            \"Training Q1\"\n",
    "        )\n",
    "        train_q2_embeddings = process_in_chunks(\n",
    "            train_df['question2'].tolist(), \n",
    "            \"Training Q2\"\n",
    "        )\n",
    "        \n",
    "        # Process test data in chunks  \n",
    "        print(\"Computing embeddings for test questions...\")\n",
    "        test_q1_embeddings = process_in_chunks(\n",
    "            test_df['question1'].tolist(),\n",
    "            \"Test Q1\"\n",
    "        )\n",
    "        test_q2_embeddings = process_in_chunks(\n",
    "            test_df['question2'].tolist(),\n",
    "            \"Test Q2\"\n",
    "        )\n",
    "        \n",
    "        print(\"Computing cosine similarities...\")\n",
    "        \n",
    "        # Process similarity computation in chunks to avoid memory issues\n",
    "        def compute_similarity_chunks(emb1, emb2, sim_chunk_size=50000):\n",
    "            similarities = []\n",
    "            \n",
    "            for i in range(0, len(emb1), sim_chunk_size):\n",
    "                end_idx = min(i + sim_chunk_size, len(emb1))\n",
    "                print(f\"Computing similarity chunk {i//sim_chunk_size + 1}/{(len(emb1)-1)//sim_chunk_size + 1}\")\n",
    "                \n",
    "                # Normalize embeddings\n",
    "                chunk_emb1 = torch.nn.functional.normalize(emb1[i:end_idx], dim=1)\n",
    "                chunk_emb2 = torch.nn.functional.normalize(emb2[i:end_idx], dim=1)\n",
    "                \n",
    "                # Compute similarity\n",
    "                chunk_sim = torch.sum(chunk_emb1 * chunk_emb2, dim=1)\n",
    "                similarities.append(chunk_sim.cpu().numpy())\n",
    "                \n",
    "                # Clear cache\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            return np.concatenate(similarities)\n",
    "        \n",
    "        # Compute similarities in chunks\n",
    "        train_similarities = compute_similarity_chunks(train_q1_embeddings, train_q2_embeddings)\n",
    "        test_similarities = compute_similarity_chunks(test_q1_embeddings, test_q2_embeddings)\n",
    "        \n",
    "        # Store results\n",
    "        train_df['embedding_cosine_similarity'] = train_similarities\n",
    "        test_df['embedding_cosine_similarity'] = test_similarities\n",
    "        \n",
    "        # Final cleanup\n",
    "        del train_q1_embeddings, train_q2_embeddings, test_q1_embeddings, test_q2_embeddings\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        print(\"GPU embedding computation completed successfully!\")\n",
    "        return train_df, test_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GPU processing failed with error: {e}\")\n",
    "        print(\"Falling back to CPU processing...\")\n",
    "        \n",
    "        # Fallback to CPU\n",
    "        return compute_embedding_similarity_cpu_fallback(train_df, test_df)\n",
    "\n",
    "\n",
    "def compute_embedding_similarity_cpu_fallback(train_df, test_df):\n",
    "    \"\"\"\n",
    "    CPU fallback function in case GPU fails\n",
    "    \"\"\"\n",
    "    print(\"Using CPU fallback...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "    \n",
    "    # Smaller batch size for CPU\n",
    "    batch_size = 16\n",
    "    \n",
    "    print(\"Computing embeddings for training data...\")\n",
    "    train_q1_embeddings = model.encode(\n",
    "        train_df['question1'].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    train_q2_embeddings = model.encode(\n",
    "        train_df['question2'].tolist(),\n",
    "        batch_size=batch_size, \n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    print(\"Computing embeddings for test data...\")\n",
    "    test_q1_embeddings = model.encode(\n",
    "        test_df['question1'].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    test_q2_embeddings = model.encode(\n",
    "        test_df['question2'].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    print(\"Computing cosine similarities...\")\n",
    "    # Normalize and compute similarity\n",
    "    train_q1_norm = train_q1_embeddings / np.linalg.norm(train_q1_embeddings, axis=1, keepdims=True)\n",
    "    train_q2_norm = train_q2_embeddings / np.linalg.norm(train_q2_embeddings, axis=1, keepdims=True)\n",
    "    test_q1_norm = test_q1_embeddings / np.linalg.norm(test_q1_embeddings, axis=1, keepdims=True)\n",
    "    test_q2_norm = test_q2_embeddings / np.linalg.norm(test_q2_embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    train_sim = np.sum(train_q1_norm * train_q2_norm, axis=1)\n",
    "    test_sim = np.sum(test_q1_norm * test_q2_norm, axis=1)\n",
    "    \n",
    "    train_df['embedding_cosine_similarity'] = train_sim\n",
    "    test_df['embedding_cosine_similarity'] = test_sim\n",
    "    \n",
    "    print(\"CPU embedding computation completed successfully!\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# Usage:\n",
    "train_df, test_df = compute_embedding_similarity(train_df, test_df, batch_size=32, chunk_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=['lenq1','lenq2','len_diff','common_words','tfidf_cosine_sim','embedding_cosine_similarity']\n",
    "X_train=train_df[feature_cols]\n",
    "y_train=train_df['is_duplicate']\n",
    "X_test=test_df[feature_cols]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Check if XGBoost can use GPU\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "\n",
    "# Configure XGBoost for GPU\n",
    "if torch.cuda.is_available():\n",
    "    xgb_params = {\n",
    "        'tree_method': 'gpu_hist',  # GPU acceleration\n",
    "        'gpu_id': 0,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1\n",
    "    }\n",
    "    print(\"Using GPU-accelerated XGBoost\")\n",
    "else:\n",
    "    xgb_params = {\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1\n",
    "    }\n",
    "    print(\"Using CPU XGBoost\")\n",
    "\n",
    "# Train model\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "cv_scores=cross_val_score(xgb_model,X_train,y_train,cv=5,scoring='accuracy')\n",
    "f1_scores=cross_val_score(xgb_model,X_train,y_train,cv=5,scoring='f1')\n",
    "roc_auc_scores=cross_val_score(xgb_model,X_train,y_train,cv=5,scoring='roc_auc')\n",
    "\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores.mean())\n",
    "print(\"Average F1 score:\", f1_scores.mean())\n",
    "print(\"Average ROC-AUC score:\", roc_auc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_test_probs=xgb_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred=(y_test_probs>=0.5).astype(int)\n",
    "#Prepare submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],         \n",
    "    'is_duplicate': y_test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c691f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvtorch (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
